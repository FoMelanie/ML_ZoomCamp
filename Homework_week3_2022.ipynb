{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2435bee",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "22875af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f02307",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01bd4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California house dataset\n",
    "data = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d716f7d",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799dad9",
   "metadata": {},
   "source": [
    "We need to keep these features:\n",
    "- 'latitude'\n",
    "- 'longitude'\n",
    "- 'housing_median_age'\n",
    "- 'total_rooms'\n",
    "- 'total_bedrooms'\n",
    "- 'population'\n",
    "- 'households'\n",
    "- 'median_income'\n",
    "- 'median_house_value'\n",
    "- 'ocean_proximity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06ada06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"housing_median_age\",\n",
    "    \"total_rooms\",\n",
    "    \"total_bedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"median_income\",\n",
    "    \"median_house_value\",\n",
    "    \"ocean_proximity\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41e84a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data = data[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b0aba",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5626013",
   "metadata": {},
   "source": [
    "## Fill in the missing values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30fb90d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                0\n",
       "longitude               0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e5acd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median of total_bedrooms\n",
    "median_bedrooms = subset_data[\"total_bedrooms\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1539aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c117c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data = subset_data.fillna(median_bedrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5e12755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude              0\n",
       "longitude             0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "ocean_proximity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb9dee",
   "metadata": {},
   "source": [
    "## Create a new column rooms_per_household by dividing the column total_rooms by the column households from dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f669153",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data['rooms_per_household'] = subset_data['total_rooms']/subset_data['households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f9aeb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        6.984127\n",
       "1        6.238137\n",
       "2        8.288136\n",
       "3        5.817352\n",
       "4        6.281853\n",
       "           ...   \n",
       "20635    5.045455\n",
       "20636    6.114035\n",
       "20637    5.205543\n",
       "20638    5.329513\n",
       "20639    5.254717\n",
       "Name: rooms_per_household, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data['rooms_per_household']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af983247",
   "metadata": {},
   "source": [
    "## Create a new column bedrooms_per_room by dividing the column total_bedrooms by the column total_rooms from dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec40950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data['bedrooms_per_room'] = subset_data['total_bedrooms']/subset_data['total_rooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bf8f062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.146591\n",
       "1        0.155797\n",
       "2        0.129516\n",
       "3        0.184458\n",
       "4        0.172096\n",
       "           ...   \n",
       "20635    0.224625\n",
       "20636    0.215208\n",
       "20637    0.215173\n",
       "20638    0.219892\n",
       "20639    0.221185\n",
       "Name: bedrooms_per_room, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data['bedrooms_per_room']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067bdef",
   "metadata": {},
   "source": [
    "## Create a new column population_per_household by dividing the column population by the column households from dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed34ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data['population_per_household'] = subset_data['population']/subset_data['households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d6f2bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.555556\n",
       "1        2.109842\n",
       "2        2.802260\n",
       "3        2.547945\n",
       "4        2.181467\n",
       "           ...   \n",
       "20635    2.560606\n",
       "20636    3.122807\n",
       "20637    2.325635\n",
       "20638    2.123209\n",
       "20639    2.616981\n",
       "Name: population_per_household, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data['population_per_household']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0049e5b",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290ea83d",
   "metadata": {},
   "source": [
    "What is the most frequent observation (mode) for the column ocean_proximity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96481a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <1H OCEAN\n",
       "Name: ocean_proximity, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data['ocean_proximity'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e4d52",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38210144",
   "metadata": {},
   "source": [
    "Create the correlation matrix for the numerical features of your train dataset.\n",
    "- In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70ec75c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                    float64\n",
       "longitude                   float64\n",
       "housing_median_age          float64\n",
       "total_rooms                 float64\n",
       "total_bedrooms              float64\n",
       "population                  float64\n",
       "households                  float64\n",
       "median_income               float64\n",
       "median_house_value          float64\n",
       "ocean_proximity              object\n",
       "rooms_per_household         float64\n",
       "bedrooms_per_room           float64\n",
       "population_per_household    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select numerical features of the dataset\n",
    "subset_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a75fb4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = subset_data.columns.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fccf2e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude',\n",
       " 'longitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income',\n",
       " 'median_house_value',\n",
       " 'ocean_proximity',\n",
       " 'rooms_per_household',\n",
       " 'bedrooms_per_room',\n",
       " 'population_per_household']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0040466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melanie\\AppData\\Local\\Temp\\ipykernel_28108\\455652441.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  corr_matrix = subset_data.corr()\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = subset_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f42c435c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>bedrooms_per_room</th>\n",
       "      <th>population_per_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.924664</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>-0.036100</td>\n",
       "      <td>-0.066484</td>\n",
       "      <td>-0.108785</td>\n",
       "      <td>-0.071035</td>\n",
       "      <td>-0.079809</td>\n",
       "      <td>-0.144160</td>\n",
       "      <td>0.106389</td>\n",
       "      <td>-0.098619</td>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-0.924664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.108197</td>\n",
       "      <td>0.044568</td>\n",
       "      <td>0.069120</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.055310</td>\n",
       "      <td>-0.015176</td>\n",
       "      <td>-0.045967</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>0.081205</td>\n",
       "      <td>0.002476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_median_age</th>\n",
       "      <td>0.011173</td>\n",
       "      <td>-0.108197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.361262</td>\n",
       "      <td>-0.319026</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>-0.302916</td>\n",
       "      <td>-0.119034</td>\n",
       "      <td>0.105623</td>\n",
       "      <td>-0.153277</td>\n",
       "      <td>0.135622</td>\n",
       "      <td>0.013191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>-0.036100</td>\n",
       "      <td>0.044568</td>\n",
       "      <td>-0.361262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927058</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.918484</td>\n",
       "      <td>0.198050</td>\n",
       "      <td>0.134153</td>\n",
       "      <td>0.133798</td>\n",
       "      <td>-0.187381</td>\n",
       "      <td>-0.024581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>-0.066484</td>\n",
       "      <td>0.069120</td>\n",
       "      <td>-0.319026</td>\n",
       "      <td>0.927058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873535</td>\n",
       "      <td>0.974366</td>\n",
       "      <td>-0.007617</td>\n",
       "      <td>0.049457</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.071649</td>\n",
       "      <td>-0.028325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>-0.108785</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.873535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907222</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>-0.024650</td>\n",
       "      <td>-0.072213</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.069863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>-0.071035</td>\n",
       "      <td>0.055310</td>\n",
       "      <td>-0.302916</td>\n",
       "      <td>0.918484</td>\n",
       "      <td>0.974366</td>\n",
       "      <td>0.907222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>0.065843</td>\n",
       "      <td>-0.080598</td>\n",
       "      <td>0.034498</td>\n",
       "      <td>-0.027309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_income</th>\n",
       "      <td>-0.079809</td>\n",
       "      <td>-0.015176</td>\n",
       "      <td>-0.119034</td>\n",
       "      <td>0.198050</td>\n",
       "      <td>-0.007617</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.688075</td>\n",
       "      <td>0.326895</td>\n",
       "      <td>-0.545298</td>\n",
       "      <td>0.018766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_house_value</th>\n",
       "      <td>-0.144160</td>\n",
       "      <td>-0.045967</td>\n",
       "      <td>0.105623</td>\n",
       "      <td>0.134153</td>\n",
       "      <td>0.049457</td>\n",
       "      <td>-0.024650</td>\n",
       "      <td>0.065843</td>\n",
       "      <td>0.688075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151948</td>\n",
       "      <td>-0.233303</td>\n",
       "      <td>-0.023737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms_per_household</th>\n",
       "      <td>0.106389</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>-0.153277</td>\n",
       "      <td>0.133798</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>-0.072213</td>\n",
       "      <td>-0.080598</td>\n",
       "      <td>0.326895</td>\n",
       "      <td>0.151948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.370308</td>\n",
       "      <td>-0.004852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms_per_room</th>\n",
       "      <td>-0.098619</td>\n",
       "      <td>0.081205</td>\n",
       "      <td>0.135622</td>\n",
       "      <td>-0.187381</td>\n",
       "      <td>0.071649</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.034498</td>\n",
       "      <td>-0.545298</td>\n",
       "      <td>-0.233303</td>\n",
       "      <td>-0.370308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population_per_household</th>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>-0.024581</td>\n",
       "      <td>-0.028325</td>\n",
       "      <td>0.069863</td>\n",
       "      <td>-0.027309</td>\n",
       "      <td>0.018766</td>\n",
       "      <td>-0.023737</td>\n",
       "      <td>-0.004852</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          latitude  longitude  housing_median_age  \\\n",
       "latitude                  1.000000  -0.924664            0.011173   \n",
       "longitude                -0.924664   1.000000           -0.108197   \n",
       "housing_median_age        0.011173  -0.108197            1.000000   \n",
       "total_rooms              -0.036100   0.044568           -0.361262   \n",
       "total_bedrooms           -0.066484   0.069120           -0.319026   \n",
       "population               -0.108785   0.099773           -0.296244   \n",
       "households               -0.071035   0.055310           -0.302916   \n",
       "median_income            -0.079809  -0.015176           -0.119034   \n",
       "median_house_value       -0.144160  -0.045967            0.105623   \n",
       "rooms_per_household       0.106389  -0.027540           -0.153277   \n",
       "bedrooms_per_room        -0.098619   0.081205            0.135622   \n",
       "population_per_household  0.002366   0.002476            0.013191   \n",
       "\n",
       "                          total_rooms  total_bedrooms  population  households  \\\n",
       "latitude                    -0.036100       -0.066484   -0.108785   -0.071035   \n",
       "longitude                    0.044568        0.069120    0.099773    0.055310   \n",
       "housing_median_age          -0.361262       -0.319026   -0.296244   -0.302916   \n",
       "total_rooms                  1.000000        0.927058    0.857126    0.918484   \n",
       "total_bedrooms               0.927058        1.000000    0.873535    0.974366   \n",
       "population                   0.857126        0.873535    1.000000    0.907222   \n",
       "households                   0.918484        0.974366    0.907222    1.000000   \n",
       "median_income                0.198050       -0.007617    0.004834    0.013033   \n",
       "median_house_value           0.134153        0.049457   -0.024650    0.065843   \n",
       "rooms_per_household          0.133798        0.001765   -0.072213   -0.080598   \n",
       "bedrooms_per_room           -0.187381        0.071649    0.010035    0.034498   \n",
       "population_per_household    -0.024581       -0.028325    0.069863   -0.027309   \n",
       "\n",
       "                          median_income  median_house_value  \\\n",
       "latitude                      -0.079809           -0.144160   \n",
       "longitude                     -0.015176           -0.045967   \n",
       "housing_median_age            -0.119034            0.105623   \n",
       "total_rooms                    0.198050            0.134153   \n",
       "total_bedrooms                -0.007617            0.049457   \n",
       "population                     0.004834           -0.024650   \n",
       "households                     0.013033            0.065843   \n",
       "median_income                  1.000000            0.688075   \n",
       "median_house_value             0.688075            1.000000   \n",
       "rooms_per_household            0.326895            0.151948   \n",
       "bedrooms_per_room             -0.545298           -0.233303   \n",
       "population_per_household       0.018766           -0.023737   \n",
       "\n",
       "                          rooms_per_household  bedrooms_per_room  \\\n",
       "latitude                             0.106389          -0.098619   \n",
       "longitude                           -0.027540           0.081205   \n",
       "housing_median_age                  -0.153277           0.135622   \n",
       "total_rooms                          0.133798          -0.187381   \n",
       "total_bedrooms                       0.001765           0.071649   \n",
       "population                          -0.072213           0.010035   \n",
       "households                          -0.080598           0.034498   \n",
       "median_income                        0.326895          -0.545298   \n",
       "median_house_value                   0.151948          -0.233303   \n",
       "rooms_per_household                  1.000000          -0.370308   \n",
       "bedrooms_per_room                   -0.370308           1.000000   \n",
       "population_per_household            -0.004852           0.002601   \n",
       "\n",
       "                          population_per_household  \n",
       "latitude                                  0.002366  \n",
       "longitude                                 0.002476  \n",
       "housing_median_age                        0.013191  \n",
       "total_rooms                              -0.024581  \n",
       "total_bedrooms                           -0.028325  \n",
       "population                                0.069863  \n",
       "households                               -0.027309  \n",
       "median_income                             0.018766  \n",
       "median_house_value                       -0.023737  \n",
       "rooms_per_household                      -0.004852  \n",
       "bedrooms_per_room                         0.002601  \n",
       "population_per_household                  1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d90e5",
   "metadata": {},
   "source": [
    "What are the two features that have the biggest correlation in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6dd383f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                  latitude                    1.000000\n",
       "longitude                 longitude                   1.000000\n",
       "bedrooms_per_room         bedrooms_per_room           1.000000\n",
       "rooms_per_household       rooms_per_household         1.000000\n",
       "median_house_value        median_house_value          1.000000\n",
       "                                                        ...   \n",
       "longitude                 population_per_household    0.002476\n",
       "latitude                  population_per_household    0.002366\n",
       "population_per_household  latitude                    0.002366\n",
       "total_bedrooms            rooms_per_household         0.001765\n",
       "rooms_per_household       total_bedrooms              0.001765\n",
       "Length: 144, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the correlation coefficients from the correlation matrix (I use the absolute value to not miss any correlation)\n",
    "ordered_correlations = abs(corr_matrix).unstack().sort_values(ascending=False)\n",
    "ordered_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aab113ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "households                total_bedrooms              0.974366\n",
      "total_bedrooms            households                  0.974366\n",
      "                          total_rooms                 0.927058\n",
      "total_rooms               total_bedrooms              0.927058\n",
      "longitude                 latitude                    0.924664\n",
      "                                                        ...   \n",
      "                          population_per_household    0.002476\n",
      "latitude                  population_per_household    0.002366\n",
      "population_per_household  latitude                    0.002366\n",
      "total_bedrooms            rooms_per_household         0.001765\n",
      "rooms_per_household       total_bedrooms              0.001765\n",
      "Length: 132, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ordered_correlations[ordered_correlations < 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db627b6b",
   "metadata": {},
   "source": [
    "The two variables 'total_bedrooms' and 'households' have the greatest correlation between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14765687",
   "metadata": {},
   "source": [
    "# Make median_house_value binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef620c2",
   "metadata": {},
   "source": [
    "We need to turn the median_house_value variable from numeric into binary.\n",
    "\n",
    "Let's create a variable above_average which is 1 if the median_house_value is above its mean value and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9dae1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206855.81690891474"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean of 'median_house_value'\n",
    "median_house_value_mean = subset_data['median_house_value'].mean()\n",
    "median_house_value_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f6502b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data['above_average'] = np.where(subset_data['median_house_value'] > median_house_value_mean, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda84fe",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f08c2",
   "metadata": {},
   "source": [
    "Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "\n",
    "Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "\n",
    "Make sure that the target value (median_house_value) is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b4fce16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First generate the full training dataset and the test dataset\n",
    "full_train, test = train_test_split(subset_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "23230313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then separate the full training dataset into train and validation datasets. We have to adjust the proportions:\n",
    "# we need 20% of the total number of rows from the 80% of values, which means we are looking for 0.25 proportion for the validation dataset\n",
    "train, val = train_test_split(full_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73c569c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I remove the 'median_house_value' from the three datasets and keep above_average as y values (I do not remove it yet)\n",
    "y_train = train['above_average']\n",
    "y_val = val['above_average']\n",
    "y_test = test['above_average']\n",
    "\n",
    "del train['median_house_value'] \n",
    "del val['median_house_value'] \n",
    "del test['median_house_value'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b7ec5",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4050e2f1",
   "metadata": {},
   "source": [
    "Calculate the mutual information score between above_average and ocean_proximity . Use the training set only.\n",
    "\n",
    "Round it to 2 decimals using round(score, 2)\n",
    "\n",
    "What is their mutual information score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8306f422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(mutual_info_score(train['above_average'], train['ocean_proximity']),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79ba64",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c5179e",
   "metadata": {},
   "source": [
    "Now let's train a logistic regression\n",
    "\n",
    "Remember that we have one categorical variable ocean_proximity in the data. Include it using one-hot encoding.\n",
    "\n",
    "Fit the model on the training dataset.\n",
    "\n",
    "To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e2aea278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'above_average' column from the features datasets\n",
    "del train['above_average'] \n",
    "del val['above_average'] \n",
    "del test['above_average'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d959a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1c0ee2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 34.43,\n",
       " 'longitude': -119.67,\n",
       " 'housing_median_age': 39.0,\n",
       " 'total_rooms': 1467.0,\n",
       " 'total_bedrooms': 381.0,\n",
       " 'population': 1404.0,\n",
       " 'households': 374.0,\n",
       " 'median_income': 2.3681,\n",
       " 'ocean_proximity': '<1H OCEAN',\n",
       " 'rooms_per_household': 3.9224598930481283,\n",
       " 'bedrooms_per_room': 0.25971370143149286,\n",
       " 'population_per_household': 3.7540106951871657}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding of 'ocean_proximity' categorical variable using DictVectorizer\n",
    "train_dicts = train.to_dict(orient='records')\n",
    "train_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b547fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate DictVectorizer\n",
    "dv = DictVectorizer(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "42a65f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit it and transform our training dataset\n",
    "X_train = dv.fit_transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1dc72dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12384, 16) (12384, 12)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of our feature matrix\n",
    "print(X_train.shape, train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b183b",
   "metadata": {},
   "source": [
    "Four columns have been added to our dataset by one-hot encoding the ocean_proximity variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0715dcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.59713701e-01, 3.74000000e+02, 3.90000000e+01, ...,\n",
       "        3.92245989e+00, 3.81000000e+02, 1.46700000e+03],\n",
       "       [1.30227981e-01, 8.06000000e+02, 2.40000000e+01, ...,\n",
       "        7.56451613e+00, 7.94000000e+02, 6.09700000e+03],\n",
       "       [2.34624146e-01, 3.37000000e+02, 4.10000000e+01, ...,\n",
       "        3.90801187e+00, 3.09000000e+02, 1.31700000e+03],\n",
       "       ...,\n",
       "       [1.82879377e-01, 6.02000000e+02, 1.80000000e+01, ...,\n",
       "        5.54983389e+00, 6.11000000e+02, 3.34100000e+03],\n",
       "       [2.29126214e-01, 3.50000000e+02, 1.60000000e+01, ...,\n",
       "        4.41428571e+00, 3.54000000e+02, 1.54500000e+03],\n",
       "       [2.09574468e-01, 2.15000000e+02, 3.50000000e+01, ...,\n",
       "        4.37209302e+00, 1.97000000e+02, 9.40000000e+02]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27183eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the logistic regression model with this new feature matrix\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "25491dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Score 0.83\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy on the train dataset\n",
    "score = model.score(X_train, y_train)\n",
    "print(\"Training Accuracy Score\", round(score,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f5cd144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X_val as I prepared X_train:\n",
    "val_dicts = val.to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_val = dv.fit_transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "90de4069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy Score 0.84\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy on the validation dataset\n",
    "score = model.score(X_val, y_val)\n",
    "print(\"Validation Accuracy Score\", round(score,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1ebf9",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d00883",
   "metadata": {},
   "source": [
    "Let's find the least useful feature using the feature elimination technique.\n",
    "- Train a model with all these features (using the same parameters as in Q4).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "- Which of following feature has the smallest difference?\n",
    "\n",
    "total_rooms\n",
    "\n",
    "total_bedrooms\n",
    "\n",
    "population\n",
    "\n",
    "households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a576b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_accuracy(feature_list, train_df, val_df, test_df, y_train, y_val, y_test):\n",
    "    \n",
    "    # Clearly state the features used\n",
    "    print(f\"The features used are {feature_list}.\")\n",
    "    \n",
    "    # Keep the feature list in our feature dataframes\n",
    "    train_features = train_df[feature_list]\n",
    "    val_features = val_df[feature_list]\n",
    "    test_features = test_df[feature_list]\n",
    "    \n",
    "    # Create the corresponding feature matrices\n",
    "    ## Train\n",
    "    train_dicts = train_features.to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train_features = dv.fit_transform(train_dicts)\n",
    "    ## Val\n",
    "    val_dicts = val_features.to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_val_features = dv.fit_transform(val_dicts)\n",
    "    ## Test\n",
    "    test_dicts = test_features.to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_test_features = dv.fit_transform(test_dicts)\n",
    "    \n",
    "    # Train the model with these features:\n",
    "    model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_features, y_train)\n",
    "    \n",
    "    # Accuracy on the train dataset\n",
    "    score_train = model.score(X_train_features, y_train)\n",
    "    print(\"Training Accuracy Score\", round(score_train,3))\n",
    "    # Accuracy on the validation set\n",
    "    score_val = model.score(X_val_features, y_val)\n",
    "    print(\"Validation Accuracy Score\", round(score_val,3))\n",
    "    # Accuracy on the test set\n",
    "    score_test = model.score(X_test_features, y_test)\n",
    "    print(\"Test Accuracy Score\", round(score_test,3))\n",
    "    \n",
    "    return score_train, score_val, score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "09041dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['total_rooms', 'total_bedrooms', 'population', 'households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d9049a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used are ['total_rooms', 'total_bedrooms', 'population', 'households'].\n",
      "Training Accuracy Score 0.698\n",
      "Validation Accuracy Score 0.71\n",
      "Test Accuracy Score 0.704\n"
     ]
    }
   ],
   "source": [
    "score_train_all, score_val_all, score_test_all = logistic_regression_accuracy(features_to_keep,\n",
    "                                                                             train,\n",
    "                                                                             val,\n",
    "                                                                             test,\n",
    "                                                                             y_train,\n",
    "                                                                             y_val,\n",
    "                                                                             y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b98c22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_without_total_rooms = ['total_bedrooms', 'population', 'households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eb544b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used are ['total_bedrooms', 'population', 'households'].\n",
      "Training Accuracy Score 0.621\n",
      "Validation Accuracy Score 0.628\n",
      "Test Accuracy Score 0.622\n"
     ]
    }
   ],
   "source": [
    "score_train_all, score_val_all, score_test_all = logistic_regression_accuracy(features_without_total_rooms,\n",
    "                                                                             train,\n",
    "                                                                             val,\n",
    "                                                                             test,\n",
    "                                                                             y_train,\n",
    "                                                                             y_val,\n",
    "                                                                             y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5bd79d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_without_total_bedrooms = ['total_rooms', 'population', 'households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4512c63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used are ['total_rooms', 'population', 'households'].\n",
      "Training Accuracy Score 0.653\n",
      "Validation Accuracy Score 0.661\n",
      "Test Accuracy Score 0.655\n"
     ]
    }
   ],
   "source": [
    "score_train_all, score_val_all, score_test_all = logistic_regression_accuracy(features_without_total_bedrooms,\n",
    "                                                                             train,\n",
    "                                                                             val,\n",
    "                                                                             test,\n",
    "                                                                             y_train,\n",
    "                                                                             y_val,\n",
    "                                                                             y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ed610191",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_without_population = ['total_rooms', 'total_bedrooms','households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a86fd27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used are ['total_rooms', 'total_bedrooms', 'households'].\n",
      "Training Accuracy Score 0.647\n",
      "Validation Accuracy Score 0.657\n",
      "Test Accuracy Score 0.654\n"
     ]
    }
   ],
   "source": [
    "score_train_all, score_val_all, score_test_all = logistic_regression_accuracy(features_without_population,\n",
    "                                                                             train,\n",
    "                                                                             val,\n",
    "                                                                             test,\n",
    "                                                                             y_train,\n",
    "                                                                             y_val,\n",
    "                                                                             y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4ae65c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_without_households = ['total_rooms', 'total_bedrooms', 'population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "15f930dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used are ['total_rooms', 'total_bedrooms', 'population'].\n",
      "Training Accuracy Score 0.667\n",
      "Validation Accuracy Score 0.672\n",
      "Test Accuracy Score 0.675\n"
     ]
    }
   ],
   "source": [
    "score_train_all, score_val_all, score_test_all = logistic_regression_accuracy(features_without_households,\n",
    "                                                                             train,\n",
    "                                                                             val,\n",
    "                                                                             test,\n",
    "                                                                             y_train,\n",
    "                                                                             y_val,\n",
    "                                                                             y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7acc4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference in accuracy for the validation dataset for each feature compared to all features:\n",
    "diff_total_rooms = 0.71-0.628\n",
    "diff_total_bedrooms = 0.71-0.661\n",
    "diff_population = 0.71-0.657\n",
    "diff_households = 0.71-0.672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cf6be6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy difference between all features and total_rooms is: 0.08.\n",
      "The accuracy difference between all features and total_bedrooms is: 0.05.\n",
      "The accuracy difference between all features and households is: 0.04.\n",
      "The accuracy difference between all features and population is: 0.05.\n"
     ]
    }
   ],
   "source": [
    "# Print the differences:\n",
    "print(f\"The accuracy difference between all features and total_rooms is: {round(diff_total_rooms,2)}.\")\n",
    "print(f\"The accuracy difference between all features and total_bedrooms is: {round(diff_total_bedrooms,2)}.\")\n",
    "print(f\"The accuracy difference between all features and households is: {round(diff_households,2)}.\")\n",
    "print(f\"The accuracy difference between all features and population is: {round(diff_population,2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830431d",
   "metadata": {},
   "source": [
    "The \"households\" variable presents the smallest difference compared to all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbcefc3",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aa3842",
   "metadata": {},
   "source": [
    "For this question, we'll see how to use a linear regression model from Scikit-Learn\n",
    "\n",
    "We'll need to use the original column 'median_house_value'. Apply the logarithmic transformation to this column.\n",
    "\n",
    "Fit the Ridge regression model (model = Ridge(alpha=a, solver=\"sag\", random_state=42)) on the training data.\n",
    "\n",
    "This model has a parameter alpha. Let's try the following values: [0, 0.01, 0.1, 1, 10]\n",
    "\n",
    "Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c052a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I remove the 'median_house_value' from the three datasets and keep above_average as y values (I do not remove it yet)\n",
    "y_train = train['median_house_value']\n",
    "y_val = val['median_house_value']\n",
    "y_test = test['median_house_value']\n",
    "\n",
    "del train['median_house_value'] \n",
    "del val['median_house_value'] \n",
    "del test['median_house_value'] \n",
    "\n",
    "# Also delete the 'above_average' column (data leakage)\n",
    "del train['above_average'] \n",
    "del val['above_average'] \n",
    "del test['above_average'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a7044a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply logarithmic transformation to the column\n",
    "y_train = np.log1p(y_train)\n",
    "y_val = np.log1p(y_val)\n",
    "y_test = np.log1p(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6bb8a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "def prepare_feature_matrices(train,val,test):\n",
    "    \n",
    "    train_dicts = train.to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "    \n",
    "    val_dicts = val.to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_val = dv.fit_transform(val_dicts)\n",
    "    \n",
    "    test_dicts = test.to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_test = dv.fit_transform(test_dicts)\n",
    "    \n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8201e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature matrices\n",
    "X_train, X_val, X_test = prepare_feature_matrices(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2b865156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rmse(y_pred, y_true):\n",
    "    \n",
    "    error = y_pred-y_true\n",
    "    mse = (error**2).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "69a57f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the RMSE values on the validation dataset with Ridge trained on train dataset\n",
    "def rmse_validation_ridge(X_train, X_val, y_train, y_val, alpha):\n",
    "    \n",
    "    model = Ridge(alpha=alpha, solver=\"sag\", random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_val = model.predict(X_val)\n",
    "    rmse_val = generate_rmse(y_pred_val,y_val)\n",
    "    \n",
    "    print(f\"The obtained RMSE on the validation dataset with alpha={alpha} is {round(rmse_val,3)}.\")\n",
    "    \n",
    "    return round(rmse_val,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6a8c58e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melanie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The obtained RMSE on the validation dataset with alpha=0 is 0.523.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melanie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The obtained RMSE on the validation dataset with alpha=0.01 is 0.523.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melanie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The obtained RMSE on the validation dataset with alpha=0.1 is 0.523.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melanie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The obtained RMSE on the validation dataset with alpha=1 is 0.523.\n",
      "The obtained RMSE on the validation dataset with alpha=10 is 0.523.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melanie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit a Ridge regression model on the training dataset with the list of alpha parameters\n",
    "rmse_val_list = []\n",
    "alpha_list = [0, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    rmse_value = rmse_validation_ridge(X_train, X_val, y_train, y_val, alpha)\n",
    "    rmse_val_list.append(rmse_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ea2f8ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.523, 0.523, 0.523, 0.523, 0.523]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_val_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5dde1a",
   "metadata": {},
   "source": [
    "The smallest RMSE value is obtained with alpha=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb279bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
